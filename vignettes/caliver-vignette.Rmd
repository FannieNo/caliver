---
title: "caliver: CALIbration and VERification of gridded model outputs"
author: ""
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r echo=FALSE}
knitr::opts_chunk$set(
  comment = '#>',
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  eval = FALSE
)
```

The package [caliver](https://cran.r-project.org/package=caliver) contains utility functions for the post-processing, calibration and validation of gridded model outputs. Initial test cases include the outputs of the following forest fire models: GEFF and RISICO.

## Dependencies and installation

Install [cdo](https://code.zmaw.de/projects/cdo/wiki) and the following packages before attempting to install caliver:

```{r}
packs <- c("devtools", "rgdal", "sp", "leaflet", "testthat", "knitr", "rmarkdown")
new.packages <- packs[!(packs %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
```

Get the development version from github using [devtools](https://github.com/hadley/devtools):

```{r}
devtools::install_github("anywhereProject/caliver")
```

Load the caliver package:

```{r}
library("caliver")
```

## Set working directory
Define the data folder, where the results will be stored
```{r}
setwd("/var/tmp/moc0/geff/results")
```

## Workflow type A: decompress single variable files and merge them over the time dimension
Define the data folder and decompress all the files in a given folder (from *.nc.gz to *.nc)
```{r}
decompressGZ(dirs = "/var/tmp/moc0/forestfire", keep = FALSE)
```

Merge all the files (with name starting with *startingString*) over the time dimension
```{r}
mergedFile <- mergetime(dirs = "/var/tmp/moc0/forestfire", 
                        startingString = "geff_reanalysis_an_fwis_fwi_")
```

## Workflow type B: Calculate quantiles
Given a netcdf file with 3 dimensions (lat, lon and time), we can calculate quantiles cell by cell:
```{r}
mergedFile <- paste0(getwd(), "/outfile.nc")
```

Get maps for given quantiles
```{r}
probsMaps <- getGriddedCDF(ncfile = mergedFile, 
                           probs = c(50, 75, 90, 99))
```

The above command generates 4 probability maps that can be further manipulated and/or plotted.

## Workflow type C: Plot multiple maps
In order to conveniently plot the results of workflow B, the maps should be shifted horizontally. This is because data from global climate models are set to have longitude between 0 and 360, while for the majority of other standard longitudes vary between -180 and +180 degrees. The shift (or rotation) can be achieved in two ways: either using the \code{raster::rotate()} function or \code{sellonlatbox} from the cdo library.

```{r}
# Option A: use the raster::rotate() function
shiftedMaps <- lapply(X = probsMaps, FUN = function(x){raster::rotate(x)})

# Option B: use sellonlatbox from the cdo library
listOfFiles <- as.character(lapply(X = probsMaps, 
                                   FUN = function(x){x@file@name}))
shiftedMaps <- raster::stack(shiftMap(inFile = listOfFiles))
```

Plot maps with background
```{r}
p <- rasterVis::levelplot(raster::stack(shiftedMaps), 
                          col.regions = rev(grDevices::heat.colors(20)), 
                          colorkey = list(space = "right"))
# Define a background map
backgroundMap <- rworldmap::getMap(resolution = "low")
p <- p + 
  latticeExtra::layer(sp::sp.lines(backgroundMap, lwd=0.8, col='darkgray'))

print(p)
```

The same plot can be achieved using the command \code{plotPercentiles()}. This has the advantage of incorporating rotation of longitudes, if necessary.
```{r}
plotPercentiles(maps = probsMaps, backgroundMap = TRUE, rotateMap = TRUE)
plotPercentiles(maps = shiftedMaps, backgroundMap = TRUE, rotateMap = FALSE)
```

## Workflow type D: extract one variable from multi-variable files, calculate CDF and plot quantiles

Define the data folder
```{r}
dirs <- "/var/tmp/moc0/geff/data/"
varname <- "fwi"
ncfile <- paste0(varname,".nc")
```

Merge all the files (with name starting with *startingString*) over the time dimension
```{r}
mergedFile <- mergetime(dirs = dirs,
                        varname = varname, 
                        startingString = "",
                        recursive = TRUE, 
                        outFile = ncfile)
```

Calculate CDF and percentiles
```{r}
listOfMaps <- getGriddedCDF(mergedFile)
```

Plot maps
```{r}
plotPercentiles(maps = listOfMaps, rotateMap = TRUE)
```

## Workflow type E: mask unrealistic values
In absence of vegetation the risk of ignition reduces to zero, regardless of the state of the soil. To exclude these areas (deserts, glaciers, urban areas, etc.) we apply a mask to the raster map of percentiles calculated above. We identify non-vegetated areas using the fuel_model map provided by JRC. 
```{r}
mergedFile <- "fwi.nc"

maskedMaps <- getGriddedCDF(ncfile = mergedFile, 
                            probs = c(50, 75, 90, 99), 
                            mask = "fuel_model")
# Plot
plotPercentiles(maps = maskedMaps, rotateMap = TRUE)
```

The layer "fuel\_model" is sored in the data folder of the caliver package and can be used to mask any other raster, e.g. the maps of fwi-dc-ffmc percentiles.

## Workflow type F: visualise the 99th percentile for Europe only (using GFED basis regions)
The example below shows how to plot fwi percentiles for Europe using an irregular polygon provided by the GFED basis regions (available here: www.globalfiredata.org/data.html)
```{r}
mergedFile <- "fwi.nc"

# Mask & crop
croppedMaps <- getGriddedCDF(ncfile = mergedFile, 
                             probs = 99,
                             mask = "fuel_model",
                             region = "EURO")

# Plot
plotPercentiles(maps = croppedMaps, backgroundMap = TRUE, rotateMap = FALSE)
plotPercentiles(maps = croppedMaps, backgroundMap = FALSE, 
                rotateMap = TRUE, cropMap = TRUE, region = "EURO")
```

Note that to centre the map to Europe we need to crop the map twice!

## Workflow type G: calculate CDF by region
The first step is to get a map for a reasonable number of percentiles so that the CDF can be constructed smoothly
```{r}
library(ggplot2)

# Define the input data folder (this contains all GEFF-reanalysis data)
dirs <- "/var/tmp/moc0/geff/data/"

# Define the list of regions
regions <- c("GLOB", "BONA", "TENA", "CEAM", "NHSA", "SHSA", "EURO", 
             "MIDE", "NHAF", "SHAF", "BOAS", "CEAS", "SEAS", "EQAS", "AUST")

data(GFEDregions)
data(fuelmodel)
  
for (varname in c("fwi", "dc", "ffmc")){
  
  ncfile <- paste0(varname,".nc")
  
  # Merge all the files (with name starting with *startingString*) 
  # over the time dimension
  mergedFile <- mergetime(dirs = dirs,
                          varname = varname,
                          startingString = "",
                          recursive = TRUE,
                          outFile = ncfile)
  
  # Set the list of probabilities to calculate
  probs <- c(seq(5,95, by = 5),99)
  ncfile <- paste0(getwd(), "/", varname, ".nc")
  # Calculate percentiles (globally)
  listOfMaps <- getGriddedCDF(ncfile = ncfile, probs = probs)
  
  # Then create CDF curves by averaging the percentiles over a given area
  CDF <- data.frame(matrix(NA, 
                           ncol = length(regions) + 1, 
                           nrow = length(probs)))
  names(CDF) <- c("percentile", regions)
  CDF$percentile <- probs
  
  for (region in regions){
    
    print(region)
    j <- which(names(CDF) == region) # counter over the columns
    
    # Mask the percentile maps using regional masks
    for (prob in probs){
      
      i <- which(CDF$percentile == prob)
      globalMap <- raster::raster(paste0(varname, "_", prob, ".nc"))
      globalMap_fuelonly <- raster::mask(globalMap, fuelmodel)
      
      if (region == "GLOB"){  
        maskedMap <- globalMap_fuelonly
      }else{
        regionMap <- regionalMask(region)
        maskedMap <- raster::mask(globalMap_fuelonly, regionMap)
      }
      
      CDF[i, j] <- round(mean(maskedMap@data@values, na.rm=TRUE), 3)
      
    }
    
  }
  saveRDS(CDF, paste0(varname, "_CDF.rds"))

  CDFmelt <- reshape2::melt(data = CDF, id.vars = names(CDF)[1])
  ggplot(data = CDFmelt, aes(x=value, y=percentile)) +
    geom_line(aes(colour=variable)) + 
    ggtitle("CDF by GFED basis regions")
}
```

## Workflow type H: calculate thresholds by region
```{r}
# Set working directory
setwd("/var/tmp/moc0/geff/CDF")
# Define the list of regions
regions <- c("GLOB", "BONA", "TENA", "CEAM", "NHSA", "SHSA", "EURO", 
             "MIDE", "NHAF", "SHAF", "BOAS", "CEAS", "SEAS", "EQAS", "AUST")
thresholds <- data.frame(matrix(NA, ncol = 2 + length(regions), nrow = 3*4))
names(thresholds) <- c("Varname", "Potential Risk Threshold", regions)
thresholds$`Potential Risk Threshold` <- c("Low", "Medium", "High", "Extreme")
i <- 1
for (varname in c("fwi", "dc", "ffmc")){
  df <- readRDS(paste0(varname, "_CDF.rds"))
  thresholds[i:(i+3),1] <- varname
  thresholds[i,3:dim(thresholds)[2]] <- df[which(df$percentile == 50), 2:dim(df)[2]]
  thresholds[i+1,3:dim(thresholds)[2]] <- df[which(df$percentile == 75), 2:dim(df)[2]]
  thresholds[i+2,3:dim(thresholds)[2]] <- df[which(df$percentile == 90), 2:dim(df)[2]]
  thresholds[i+3,3:dim(thresholds)[2]] <- df[which(df$percentile == 99), 2:dim(df)[2]]
  i <- i + 4
}

thresholds[,3:17] <- thresholds[,3:17]
saveRDS(thresholds, "thresholds.RDS")
```

## Workflow type I: validate burned areas
```{r}
# Set working directory
setwd("/var/tmp/moc0/geff/observations")

obs <- mergetime(dirs = getwd(),
                 varname = "BurnedArea", startingString = "",
                 recursive = FALSE, outFile = "BurnedArea.nc")
obs <- raster::brick(obs)
# Aggregate every 4 cells to match resolution of FWI layer
obs_aggregated <- raster::aggregate(obs, fact = 4, fun=mean)
# saveRDS(obs_aggregated, "obs_aggregated.rds")
# obs_aggregated <- readRDS("obs_aggregated.rds")

for (thresholdFWI in c(50, 75, 90, 99)){
  
  i <- which(c(50, 75, 90, 99) == thresholdFWI)
  
  fwi <- raster::raster(paste0("/var/tmp/moc0/geff/results/fwi_", 
                               thresholdFWI, ".nc"))
  
  if (thresholdFWI == 50) {
    obs_aggregated_resampled <- raster::resample(obs_aggregated, fwi)
    # Check rasters have same extent, neede for comparisons
    # raster::compareRaster(obs_aggregated_resampled, fwi)
    saveRDS(obs_aggregated_resampled, "obs_aggregated_resampled.rds")
    # obs_aggregated_resampled <- readRDS("obs_aggregated_resampled.rds")
    
    thresholdBurntArea <- 20
    burnt <- raster::calc(obs_aggregated_resampled,
                          function(x){ifelse(test = x < thresholdBurntArea/100,
                                             yes = 0, no = 1)})
    burnt_sum <- raster::stackApply(x = burnt, indices = 1, fun = sum)
    
    burnt <- data.frame(as.vector(matrix(burnt_sum)))
    idx <- which(burnt > 0)
    names(burnt) <- "BurnedCount"
    burnt$BurnedAreas <- FALSE
    burnt$BurnedAreas[idx] <- TRUE
  }
  
  burnt <- cbind(burnt, as.vector(matrix(fwi)))
  names(burnt)[2+i] <- paste0("FWI", thresholdFWI)
}

library(ggplot2)
library(reshape2)
burntMelt <- melt(burnt, id.vars = c("BurnedCount", "BurnedAreas"))
saveRDS(burntMelt, "burntMelt.rds")
# burntMelt <- readRDS("burntMelt.rds")
ggplot(burntMelt, aes(x=value, fill=BurnedAreas)) + 
  geom_density(alpha=.3, color = NA) + 
  facet_wrap(~ variable, scales = "free_y") + theme_bw() + xlab("")
```
